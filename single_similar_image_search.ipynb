{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train data: 70379 rows, test categories: 30205 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2109117/972923432.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring index to GPU...\n",
      "Index transferred to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Category to attribute mapping\n",
    "category_class_attribute_mapping = {\n",
    "    'Kurtis': {\n",
    "        'color': 'attr_1',\n",
    "        'fit_shape': 'attr_2',\n",
    "        'length': 'attr_3',\n",
    "        'occasion': 'attr_4',\n",
    "        'ornamentation': 'attr_5',\n",
    "        'pattern': 'attr_6',\n",
    "        'print_or_pattern_type': 'attr_7',\n",
    "        'sleeve_length': 'attr_8',\n",
    "        'sleeve_styling': 'attr_9'\n",
    "    },\n",
    "    'Men Tshirts': {\n",
    "        'color': 'attr_1',\n",
    "        'neck': 'attr_2',\n",
    "        'pattern': 'attr_3',\n",
    "        'print_or_pattern_type': 'attr_4',\n",
    "        'sleeve_length': 'attr_5'\n",
    "    },\n",
    "    'Sarees': {\n",
    "        'blouse_pattern': 'attr_1',\n",
    "        'border': 'attr_2',\n",
    "        'border_width': 'attr_3',\n",
    "        'color': 'attr_4',\n",
    "        'occasion': 'attr_5',\n",
    "        'ornamentation': 'attr_6',\n",
    "        'pallu_details': 'attr_7',\n",
    "        'pattern': 'attr_8',\n",
    "        'print_or_pattern_type': 'attr_9',\n",
    "        'transparency': 'attr_10'\n",
    "    },\n",
    "    'Women Tops & Tunics': {\n",
    "        'color': 'attr_1',\n",
    "        'fit_shape': 'attr_2',\n",
    "        'length': 'attr_3',\n",
    "        'neck_collar': 'attr_4',\n",
    "        'occasion': 'attr_5',\n",
    "        'pattern': 'attr_6',\n",
    "        'print_or_pattern_type': 'attr_7',\n",
    "        'sleeve_length': 'attr_8',\n",
    "        'sleeve_styling': 'attr_9',\n",
    "        'surface_styling': 'attr_10'\n",
    "    },\n",
    "    'Women Tshirts': {\n",
    "        'color': 'attr_1',\n",
    "        'fit_shape': 'attr_2',\n",
    "        'length': 'attr_3',\n",
    "        'pattern': 'attr_4',\n",
    "        'print_or_pattern_type': 'attr_5',\n",
    "        'sleeve_length': 'attr_6',\n",
    "        'sleeve_styling': 'attr_7',\n",
    "        'surface_styling': 'attr_8'\n",
    "    }\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import clip\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import math\n",
    "\n",
    "class CLIPEmbedder:\n",
    "    def __init__(self, checkpoint_path: str = None, device: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the CLIP embedder with an optional custom checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_path: Path to the checkpoint containing CLIP model weights\n",
    "            device: Device to run the model on ('cuda' or 'cpu'). If None, automatically detected.\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") if device is None else torch.device(device)\n",
    "        \n",
    "        # Load the base CLIP model and preprocessor\n",
    "        self.model, self.preprocess = clip.load(\"ViT-L/14\", device=self.device)\n",
    "        \n",
    "        # Load custom weights if provided\n",
    "        if checkpoint_path:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'clip_model_state_dict' not in checkpoint:\n",
    "                raise ValueError(\"Checkpoint does not contain 'clip_model_state_dict'\")\n",
    "            self.model.load_state_dict(checkpoint['clip_model_state_dict'])\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_single_feature(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Extract features from a single image.\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            pixel_values = self.preprocess(image).unsqueeze(0).to(self.device)\n",
    "            features = self.model.encode_image(pixel_values)\n",
    "            image.close()\n",
    "            return features.cpu().numpy()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing image {image_path}: {str(e)}\")\n",
    "\n",
    "class FAISSIndex:\n",
    "    def __init__(self, features, filenames):\n",
    "        self.features = features\n",
    "        self.filenames = filenames\n",
    "        self.dimension = features.shape[1]\n",
    "        self.index = None\n",
    "        \n",
    "    def build_index(self):\n",
    "        features_c = np.ascontiguousarray(self.features.astype('float32'))\n",
    "        features_c = normalize(features_c)\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "        self.index.add(features_c)\n",
    "        print(\"Transferring index to GPU...\")\n",
    "        self.res = faiss.StandardGpuResources()\n",
    "        self.index = faiss.index_cpu_to_gpu(self.res, 0, self.index)\n",
    "        print(\"Index transferred to GPU.\")\n",
    "\n",
    "class SimilaritySearch:\n",
    "    def __init__(self, index, filenames, train_categories, threshold=0.55):\n",
    "        self.index = index\n",
    "        self.filenames = filenames\n",
    "        self.train_categories = train_categories  # Add train categories\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def search(self, query_features, query_category, k=10):\n",
    "        \"\"\"\n",
    "        Search for similar images within the same category\n",
    "        \n",
    "        Args:\n",
    "            query_features: Features of the query image\n",
    "            query_category: Category of the query image\n",
    "            k: Number of results to return\n",
    "        \"\"\"\n",
    "        # Get more initial results to ensure enough after category filtering\n",
    "        initial_k = k * 3\n",
    "        query_features = normalize(query_features.astype('float32'))\n",
    "        distances, indices = self.index.search(query_features, initial_k)\n",
    "        \n",
    "        results = []\n",
    "        for dist, idx in zip(distances[0], indices[0]):\n",
    "            similarity = dist\n",
    "            filename = self.filenames[idx]\n",
    "            # Only include results from the same category\n",
    "            if (similarity >= self.threshold and \n",
    "                self.train_categories.get(filename) == query_category):\n",
    "                results.append({\n",
    "                    'filename': filename,\n",
    "                    'similarity': float(similarity),\n",
    "                    'category': query_category\n",
    "                })\n",
    "        \n",
    "        # Return top k results after category filtering\n",
    "        return results\n",
    "\n",
    "class ImageVisualizer:\n",
    "    @staticmethod\n",
    "    def plot_similar_images(query_image_path: str, \n",
    "                          similar_images: pd.DataFrame, \n",
    "                          reference_image_folder: str,\n",
    "                          figsize=(15, 10)):\n",
    "        \"\"\"\n",
    "        Plot the query image and its similar matches with annotations.\n",
    "        \n",
    "        Args:\n",
    "            query_image_path: Path to the query image\n",
    "            similar_images: DataFrame containing similar image results\n",
    "            reference_image_folder: Path to the folder containing reference images\n",
    "            figsize: Size of the figure (width, height)\n",
    "        \"\"\"\n",
    "        n_similar = len(similar_images)\n",
    "        n_cols = min(5, n_similar + 1)  # +1 for query image\n",
    "        n_rows = math.ceil((n_similar + 1) / n_cols)\n",
    "        \n",
    "        # Create figure with gridspec\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = GridSpec(n_rows, n_cols, figure=fig)\n",
    "        \n",
    "        # Plot query image\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "        query_img = Image.open(query_image_path).convert('RGB')\n",
    "        ax.imshow(query_img)\n",
    "        ax.set_title('Query Image\\n' + os.path.basename(query_image_path), fontsize=8)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Plot similar images\n",
    "        for idx, row in enumerate(similar_images.itertuples()):\n",
    "            row_idx = (idx + 1) // n_cols\n",
    "            col_idx = (idx + 1) % n_cols\n",
    "            \n",
    "            ax = fig.add_subplot(gs[row_idx, col_idx])\n",
    "            \n",
    "            # Load and display similar image\n",
    "            img_path = os.path.join(reference_image_folder, row.filename) + \".png\"\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                ax.imshow(img)\n",
    "                title = f'Match {idx+1}\\nFile: {row.filename}\\nSimilarity: {row.similarity:.3f}'\n",
    "                ax.set_title(title, fontsize=8)\n",
    "                ax.axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "                ax.text(0.5, 0.5, 'Image not found', ha='center', va='center')\n",
    "                ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "class SingleImageSimilaritySearch:\n",
    "    def __init__(self, checkpoint_path: str, reference_features, reference_filenames, \n",
    "                 train_df: pd.DataFrame, test_categories_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize the similarity search system.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_path: Path to CLIP checkpoint\n",
    "            reference_features: Features of reference images\n",
    "            reference_filenames: Filenames of reference images\n",
    "            train_df: DataFrame containing training data with categories\n",
    "            test_categories_df: DataFrame containing test image categories\n",
    "        \"\"\"\n",
    "        self.feature_extractor = CLIPEmbedder(checkpoint_path)\n",
    "        self.faiss_index = FAISSIndex(reference_features, reference_filenames)\n",
    "        self.faiss_index.build_index()\n",
    "        \n",
    "        # Prepare category mappings\n",
    "        self.train_df = train_df\n",
    "        self.test_categories_df = test_categories_df\n",
    "        \n",
    "        # Create filename to category mappings\n",
    "        self.train_df['id_as_filename'] = self.train_df['id'].astype(str).str.zfill(6) + '.png'\n",
    "        self.train_categories = dict(zip(self.train_df['id_as_filename'], self.train_df['Category']))\n",
    "        \n",
    "        self.test_categories_df['id_as_filename'] = self.test_categories_df['id'].astype(str).str.zfill(6) + '.png'\n",
    "        self.test_categories = dict(zip(self.test_categories_df['id_as_filename'], self.test_categories_df['Category']))\n",
    "        \n",
    "        self.similarity_search = SimilaritySearch(\n",
    "            self.faiss_index.index, \n",
    "            reference_filenames,\n",
    "            self.train_categories,\n",
    "            threshold=0.55\n",
    "        )\n",
    "        self.visualizer = ImageVisualizer()\n",
    "    \n",
    "    def get_image_category(self, image_filename: str) -> str:\n",
    "        \"\"\"Get category for an image filename.\"\"\"\n",
    "        return self.train_categories.get(image_filename, None)\n",
    "    \n",
    "    def find_similar_images(self, image_path: str, k: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Find similar images for a single query image within the same category.\"\"\"\n",
    "        # Get query image category\n",
    "        query_filename = os.path.basename(image_path)\n",
    "        query_category = self.get_image_category(query_filename)\n",
    "        \n",
    "        if query_category is None:\n",
    "            raise ValueError(f\"Category not found for image: {query_filename}\")\n",
    "        \n",
    "        # Extract features and search\n",
    "        query_features = self.feature_extractor.extract_single_feature(image_path)\n",
    "        similar_images = self.similarity_search.search(query_features, query_category, k=k)\n",
    "        \n",
    "        results_df = pd.DataFrame(similar_images)\n",
    "        results_df['query_image'] = query_filename\n",
    "        results_df['query_category'] = query_category\n",
    "        results_df['file_path'] = f\"/scratch/data/m23csa016/train_images_bg_removed/{results_df['filename']}\"\n",
    "        return results_df[['query_image', 'query_category', 'filename', 'file_path', 'similarity']]\n",
    "    \n",
    "    def find_and_save_visualizations(self, \n",
    "                                     image_id,\n",
    "                                     image_path: str, \n",
    "                                     reference_image_folder: str, \n",
    "                                     output_folder: str,\n",
    "                                     k: int = 10,\n",
    "                                     image_size: tuple = (25, 10)):\n",
    "        \"\"\"\n",
    "        Find similar images and save each visualization plot as an image file in the specified output folder.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the query image\n",
    "            reference_image_folder: Path to the folder containing reference images\n",
    "            output_folder: Path to the folder to save individual plots\n",
    "            k: Number of similar images to find\n",
    "            image_size: Size of each plot image (width, height)\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with the results of the similarity search.\n",
    "        \"\"\"\n",
    "        results_df = self.find_similar_images(image_path, k)\n",
    "        \n",
    "        # Ensure output folder exists\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "      # Loop through each result to save a separate plot for each image\n",
    "        for idx, row in enumerate(results_df.itertuples()):\n",
    "            fig, axes = plt.subplots(1, 2, figsize=image_size)\n",
    "            \n",
    "            # Plot the query image on the left\n",
    "            query_img = Image.open(image_path).convert('RGB')\n",
    "            axes[0].imshow(query_img)\n",
    "            query_category = results_df['query_category'].iloc[0]\n",
    "            axes[0].set_title(f'Query Image\\n{os.path.basename(image_path)}\\nCategory: {query_category}', fontsize=8)\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Plot the similar image on the right\n",
    "            similar_img_path = os.path.join(reference_image_folder, row.filename)\n",
    "            try:\n",
    "                similar_img = Image.open(similar_img_path).convert('RGB')\n",
    "                axes[1].imshow(similar_img)\n",
    "                axes[1].set_title(f'Similar Image {idx+1}\\nFile: {row.filename}\\nSimilarity: {row.similarity:.3f}', fontsize=8)\n",
    "                axes[1].axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {similar_img_path}: {str(e)}\")\n",
    "                axes[1].text(0.5, 0.5, 'Image not found', ha='center', va='center')\n",
    "                axes[1].axis('off')\n",
    "            \n",
    "            # Save the individual plot\n",
    "            output_path = os.path.join(output_folder, f\"{image_id}_{idx+1}.png\")\n",
    "            fig.savefig(output_path, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "        \n",
    "        print(f\"Saved {len(results_df)} images to {output_folder}\")\n",
    "        return results_df\n",
    "    \n",
    "\n",
    "train_df = pd.read_csv('/scratch/data/m23csa016/meesho_data/new_train.csv')\n",
    "test_categories_df = pd.read_csv('/scratch/data/m23csa016/meesho_data/test.csv')\n",
    "print(f\"Loaded train data: {len(train_df)} rows, test categories: {len(test_categories_df)} rows\")\n",
    "\n",
    "# Load pre-computed embeddings\n",
    "train_features_df = pd.read_parquet('/scratch/data/m23csa016/meesho_data/cvl_nobg_max_train_em_1.parquet')\n",
    "test_features_df = pd.read_parquet('/scratch/data/m23csa016/meesho_data/cvl_nobg_max_test_em_1.parquet')\n",
    "\n",
    "feature_cols = [col for col in train_features_df.columns if col.startswith('feature_')]\n",
    "train_features = train_features_df[feature_cols].values\n",
    "train_filenames = train_features_df['filename'].tolist()\n",
    "\n",
    "searcher = SingleImageSimilaritySearch(\n",
    "    checkpoint_path=\"/scratch/data/m23csa016/meesho_data/bm_epoch_34_trainval_120024.pth\",\n",
    "    reference_features=train_features,\n",
    "    reference_filenames=train_filenames,\n",
    "    train_df=train_df,\n",
    "    test_categories_df=test_categories_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_images = \"/scratch/data/m23csa016/meesho_data/train_images_bg_removed\"\n",
    "image = \"028878.png\"\n",
    "image_path = os.path.join(train_images, image)\n",
    "output_folder = \"/iitjhome/m23csa016/meesho_code/sim_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 77 images to /iitjhome/m23csa016/meesho_code/sim_output\n"
     ]
    }
   ],
   "source": [
    "df = searcher.find_and_save_visualizations(28878, image_path, train_images, output_folder, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
