{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category to attribute mapping\n",
    "category_class_attribute_mapping = {\n",
    "    'Kurtis': {\n",
    "        'color': 'attr_1',\n",
    "        'fit_shape': 'attr_2',\n",
    "        'length': 'attr_3',\n",
    "        'occasion': 'attr_4',\n",
    "        'ornamentation': 'attr_5',\n",
    "        'pattern': 'attr_6',\n",
    "        'print_or_pattern_type': 'attr_7',\n",
    "        'sleeve_length': 'attr_8',\n",
    "        'sleeve_styling': 'attr_9'\n",
    "    },\n",
    "    'Men Tshirts': {\n",
    "        'color': 'attr_1',\n",
    "        'neck': 'attr_2',\n",
    "        'pattern': 'attr_3',\n",
    "        'print_or_pattern_type': 'attr_4',\n",
    "        'sleeve_length': 'attr_5'\n",
    "    },\n",
    "    'Sarees': {\n",
    "        'blouse_pattern': 'attr_1',\n",
    "        'border': 'attr_2',\n",
    "        'border_width': 'attr_3',\n",
    "        'color': 'attr_4',\n",
    "        'occasion': 'attr_5',\n",
    "        'ornamentation': 'attr_6',\n",
    "        'pallu_details': 'attr_7',\n",
    "        'pattern': 'attr_8',\n",
    "        'print_or_pattern_type': 'attr_9',\n",
    "        'transparency': 'attr_10'\n",
    "    },\n",
    "    'Women Tops & Tunics': {\n",
    "        'color': 'attr_1',\n",
    "        'fit_shape': 'attr_2',\n",
    "        'length': 'attr_3',\n",
    "        'neck_collar': 'attr_4',\n",
    "        'occasion': 'attr_5',\n",
    "        'pattern': 'attr_6',\n",
    "        'print_or_pattern_type': 'attr_7',\n",
    "        'sleeve_length': 'attr_8',\n",
    "        'sleeve_styling': 'attr_9',\n",
    "        'surface_styling': 'attr_10'\n",
    "    },\n",
    "    'Women Tshirts': {\n",
    "        'color': 'attr_1',\n",
    "        'fit_shape': 'attr_2',\n",
    "        'length': 'attr_3',\n",
    "        'pattern': 'attr_4',\n",
    "        'print_or_pattern_type': 'attr_5',\n",
    "        'sleeve_length': 'attr_6',\n",
    "        'sleeve_styling': 'attr_7',\n",
    "        'surface_styling': 'attr_8'\n",
    "    }\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import clip\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import math\n",
    "\n",
    "class CLIPEmbedder:\n",
    "    def __init__(self, checkpoint_path: str = None, device: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the CLIP embedder with an optional custom checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_path: Path to the checkpoint containing CLIP model weights\n",
    "            device: Device to run the model on ('cuda' or 'cpu'). If None, automatically detected.\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") if device is None else torch.device(device)\n",
    "        \n",
    "        # Load the base CLIP model and preprocessor\n",
    "        self.model, self.preprocess = clip.load(\"ViT-L/14\", device=self.device)\n",
    "        \n",
    "        # Load custom weights if provided\n",
    "        if checkpoint_path:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'clip_model_state_dict' not in checkpoint:\n",
    "                raise ValueError(\"Checkpoint does not contain 'clip_model_state_dict'\")\n",
    "            self.model.load_state_dict(checkpoint['clip_model_state_dict'])\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_single_feature(self, image_path: str) -> np.ndarray:\n",
    "        \"\"\"Extract features from a single image.\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            pixel_values = self.preprocess(image).unsqueeze(0).to(self.device)\n",
    "            features = self.model.encode_image(pixel_values)\n",
    "            image.close()\n",
    "            return features.cpu().numpy()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing image {image_path}: {str(e)}\")\n",
    "\n",
    "class FAISSIndex:\n",
    "    def __init__(self, features, filenames):\n",
    "        self.features = features\n",
    "        self.filenames = filenames\n",
    "        self.dimension = features.shape[1]\n",
    "        self.index = None\n",
    "        \n",
    "    def build_index(self):\n",
    "        features_c = np.ascontiguousarray(self.features.astype('float32'))\n",
    "        features_c = normalize(features_c)\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "        self.index.add(features_c)\n",
    "        print(\"Transferring index to GPU...\")\n",
    "        self.res = faiss.StandardGpuResources()\n",
    "        self.index = faiss.index_cpu_to_gpu(self.res, 0, self.index)\n",
    "        print(\"Index transferred to GPU.\")\n",
    "\n",
    "class SimilaritySearch:\n",
    "    def __init__(self, index, filenames, train_categories, threshold=0.75):\n",
    "        self.index = index\n",
    "        self.filenames = filenames\n",
    "        self.train_categories = train_categories  # Add train categories\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def search(self, query_features, query_category, k=10):\n",
    "        \"\"\"\n",
    "        Search for similar images within the same category\n",
    "        \n",
    "        Args:\n",
    "            query_features: Features of the query image\n",
    "            query_category: Category of the query image\n",
    "            k: Number of results to return\n",
    "        \"\"\"\n",
    "        # Get more initial results to ensure enough after category filtering\n",
    "        initial_k = k * 3\n",
    "        query_features = normalize(query_features.astype('float32'))\n",
    "        distances, indices = self.index.search(query_features, initial_k)\n",
    "        \n",
    "        results = []\n",
    "        for dist, idx in zip(distances[0], indices[0]):\n",
    "            similarity = dist\n",
    "            filename = self.filenames[idx]\n",
    "            # Only include results from the same category\n",
    "            if (similarity >= self.threshold and \n",
    "                self.train_categories.get(filename) == query_category):\n",
    "                results.append({\n",
    "                    'filename': filename,\n",
    "                    'similarity': float(similarity),\n",
    "                    'category': query_category\n",
    "                })\n",
    "        \n",
    "        # Return top k results after category filtering\n",
    "        return results\n",
    "\n",
    "class ImageVisualizer:\n",
    "    @staticmethod\n",
    "    def plot_similar_images(query_image_path: str, \n",
    "                          similar_images: pd.DataFrame, \n",
    "                          reference_image_folder: str,\n",
    "                          figsize=(15, 10)):\n",
    "        \"\"\"\n",
    "        Plot the query image and its similar matches with annotations.\n",
    "        \n",
    "        Args:\n",
    "            query_image_path: Path to the query image\n",
    "            similar_images: DataFrame containing similar image results\n",
    "            reference_image_folder: Path to the folder containing reference images\n",
    "            figsize: Size of the figure (width, height)\n",
    "        \"\"\"\n",
    "        n_similar = len(similar_images)\n",
    "        n_cols = min(5, n_similar + 1)  # +1 for query image\n",
    "        n_rows = math.ceil((n_similar + 1) / n_cols)\n",
    "        \n",
    "        # Create figure with gridspec\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = GridSpec(n_rows, n_cols, figure=fig)\n",
    "        \n",
    "        # Plot query image\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "        query_img = Image.open(query_image_path).convert('RGB')\n",
    "        ax.imshow(query_img)\n",
    "        ax.set_title('Query Image\\n' + os.path.basename(query_image_path), fontsize=8)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Plot similar images\n",
    "        for idx, row in enumerate(similar_images.itertuples()):\n",
    "            row_idx = (idx + 1) // n_cols\n",
    "            col_idx = (idx + 1) % n_cols\n",
    "            \n",
    "            ax = fig.add_subplot(gs[row_idx, col_idx])\n",
    "            \n",
    "            # Load and display similar image\n",
    "            img_path = os.path.join(reference_image_folder, row.filename) + \".png\"\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                ax.imshow(img)\n",
    "                title = f'Match {idx+1}\\nFile: {row.filename}\\nSimilarity: {row.similarity:.3f}'\n",
    "                ax.set_title(title, fontsize=8)\n",
    "                ax.axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "                ax.text(0.5, 0.5, 'Image not found', ha='center', va='center')\n",
    "                ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "class SingleImageSimilaritySearch:\n",
    "    def __init__(self, checkpoint_path: str, reference_features, reference_filenames, \n",
    "                 train_df: pd.DataFrame, test_categories_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize the similarity search system.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_path: Path to CLIP checkpoint\n",
    "            reference_features: Features of reference images\n",
    "            reference_filenames: Filenames of reference images\n",
    "            train_df: DataFrame containing training data with categories\n",
    "            test_categories_df: DataFrame containing test image categories\n",
    "        \"\"\"\n",
    "        self.feature_extractor = CLIPEmbedder(checkpoint_path)\n",
    "        self.faiss_index = FAISSIndex(reference_features, reference_filenames)\n",
    "        self.faiss_index.build_index()\n",
    "        \n",
    "        # Prepare category mappings\n",
    "        self.train_df = train_df\n",
    "        self.test_categories_df = test_categories_df\n",
    "        \n",
    "        # Create filename to category mappings\n",
    "        self.train_df['id_as_filename'] = self.train_df['id'].astype(str).str.zfill(6) + '.png'\n",
    "        self.train_categories = dict(zip(self.train_df['id_as_filename'], self.train_df['Category']))\n",
    "        \n",
    "        self.test_categories_df['id_as_filename'] = self.test_categories_df['id'].astype(str).str.zfill(6) + '.png'\n",
    "        self.test_categories = dict(zip(self.test_categories_df['id_as_filename'], self.test_categories_df['Category']))\n",
    "        \n",
    "        self.similarity_search = SimilaritySearch(\n",
    "            self.faiss_index.index, \n",
    "            reference_filenames,\n",
    "            self.train_categories,\n",
    "            threshold=0\n",
    "        )\n",
    "        self.visualizer = ImageVisualizer()\n",
    "    \n",
    "    def get_image_category(self, image_filename: str) -> str:\n",
    "        \"\"\"Get category for an image filename.\"\"\"\n",
    "        return self.test_categories.get(image_filename, None)\n",
    "    \n",
    "    def find_similar_images(self, image_path: str, k: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Find similar images for a single query image within the same category.\"\"\"\n",
    "        # Get query image category\n",
    "        query_filename = os.path.basename(image_path)\n",
    "        query_category = self.get_image_category(query_filename)\n",
    "        \n",
    "        if query_category is None:\n",
    "            raise ValueError(f\"Category not found for image: {query_filename}\")\n",
    "        \n",
    "        # Extract features and search\n",
    "        query_features = self.feature_extractor.extract_single_feature(image_path)\n",
    "        similar_images = self.similarity_search.search(query_features, query_category, k=k)\n",
    "        \n",
    "        results_df = pd.DataFrame(similar_images)\n",
    "        results_df['query_image'] = query_filename\n",
    "        results_df['query_category'] = query_category\n",
    "        return results_df[['query_image', 'query_category', 'filename', 'similarity']]\n",
    "    \n",
    "    def find_and_visualize(self, \n",
    "                          image_path: str, \n",
    "                          reference_image_folder: str,\n",
    "                          k: int = 10,\n",
    "                          figsize=(25, 10)) -> Tuple[pd.DataFrame, plt.Figure]:\n",
    "        \"\"\"\n",
    "        Find similar images within the same category and create visualization.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the query image\n",
    "            reference_image_folder: Path to the folder containing reference images\n",
    "            k: Number of similar images to find\n",
    "            figsize: Size of the output figure\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (results DataFrame, matplotlib Figure)\n",
    "        \"\"\"\n",
    "        results_df = self.find_similar_images(image_path, k)\n",
    "        \n",
    "        # Update visualizer to show category information\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = GridSpec(math.ceil((k + 1) / 5), min(5, k + 1), figure=fig)\n",
    "        \n",
    "        # Plot query image\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "        query_img = Image.open(image_path).convert('RGB')\n",
    "        ax.imshow(query_img)\n",
    "        query_category = results_df['query_category'].iloc[0]\n",
    "        ax.set_title(f'Query Image\\n{os.path.basename(image_path)}\\nCategory: {query_category}', \n",
    "                    fontsize=8)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Plot similar images\n",
    "        for idx, row in enumerate(results_df.itertuples()):\n",
    "            row_idx = (idx + 1) // 5\n",
    "            col_idx = (idx + 1) % 5\n",
    "            \n",
    "            ax = fig.add_subplot(gs[row_idx, col_idx])\n",
    "            img_path = os.path.join(reference_image_folder, row.filename) \n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                ax.imshow(img)\n",
    "                title = f'Match {idx+1}\\nFile: {row.filename}\\nSimilarity: {row.similarity:.3f}\\nCategory: {row.query_category}'\n",
    "                ax.set_title(title, fontsize=8)\n",
    "                ax.axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "                ax.text(0.5, 0.5, 'Image not found', ha='center', va='center')\n",
    "                ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return results_df, fig\n",
    "    \n",
    "\n",
    "train_df = pd.read_csv('/scratch/data/m23csa016/meesho_data/new_train.csv')\n",
    "test_categories_df = pd.read_csv('/scratch/data/m23csa016/meesho_data/test.csv')\n",
    "print(f\"Loaded train data: {len(train_df)} rows, test categories: {len(test_categories_df)} rows\")\n",
    "\n",
    "# Load pre-computed embeddings\n",
    "train_features_df = pd.read_parquet('/scratch/data/m23csa016/meesho_data/cvl_nobg_max_train_em_1.parquet')\n",
    "test_features_df = pd.read_parquet('/scratch/data/m23csa016/meesho_data/cvl_nobg_max_test_em_1.parquet')\n",
    "\n",
    "feature_cols = [col for col in train_features_df.columns if col.startswith('feature_')]\n",
    "train_features = train_features_df[feature_cols].values\n",
    "train_filenames = train_features_df['filename'].tolist()\n",
    "\n",
    "searcher = SingleImageSimilaritySearch(\n",
    "    checkpoint_path=\"/scratch/data/m23csa016/meesho_data/bm_epoch_34_trainval_120024.pth\",\n",
    "    reference_features=train_features,\n",
    "    reference_filenames=train_filenames,\n",
    "    train_df=train_df,\n",
    "    test_categories_df=test_categories_df\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from collections import Counter\n",
    "from typing import List, Optional, Dict, Any\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class CategoryAwareTrainingLabelCorrector:\n",
    "    def __init__(self, \n",
    "                 similarity_searcher: SingleImageSimilaritySearch,\n",
    "                 train_df: pd.DataFrame,\n",
    "                 category_attribute_mapping: Dict[str, Dict[str, str]],\n",
    "                 num_similar: int = 10,\n",
    "                 similarity_threshold: float = 0.7,\n",
    "                 log_dir: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the category-aware training data label corrector with enhanced logging.\n",
    "        \n",
    "        Args:\n",
    "            similarity_searcher: Initialized SingleImageSimilaritySearch object\n",
    "            train_df: Training DataFrame containing the labels\n",
    "            category_attribute_mapping: Mapping of categories to their attributes\n",
    "            num_similar: Number of similar images to consider for majority voting\n",
    "            similarity_threshold: Minimum similarity score to consider an image\n",
    "            log_dir: Directory to save detailed logs (optional)\n",
    "        \"\"\"\n",
    "        # Set up logging\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "        # Create log directory if not exists\n",
    "        self.log_dir = log_dir or os.path.join(os.getcwd(), 'label_correction_logs')\n",
    "        os.makedirs(self.log_dir, exist_ok=True)\n",
    "        \n",
    "        # Create file handler for detailed logs\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        log_file = os.path.join(self.log_dir, f'label_correction_{timestamp}.log')\n",
    "        file_handler = logging.FileHandler(log_file)\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(file_formatter)\n",
    "        self.logger.addHandler(file_handler)\n",
    "        \n",
    "        # Console handler for important messages\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setLevel(logging.WARNING)\n",
    "        console_formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "        console_handler.setFormatter(console_formatter)\n",
    "        self.logger.addHandler(console_handler)\n",
    "        \n",
    "        # Initialize other attributes\n",
    "        self.searcher = similarity_searcher\n",
    "        self.train_df = train_df\n",
    "        self.category_attribute_mapping = category_attribute_mapping\n",
    "        self.num_similar = num_similar\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        \n",
    "        # Create a mapping from filename to row index for faster lookups\n",
    "        self.train_df['filename'] = self.train_df['id'].astype(str).str.zfill(6) + '.png'\n",
    "        self.filename_to_idx = dict(zip(self.train_df['filename'], self.train_df.index))\n",
    "        \n",
    "        # Create reverse mapping (attr_1 -> attribute name) for each category\n",
    "        self.reverse_attribute_mapping = {\n",
    "            category: {v: k for k, v in attrs.items()}\n",
    "            for category, attrs in category_attribute_mapping.items()\n",
    "        }\n",
    "        \n",
    "        # Log initialization details\n",
    "        self.logger.info(f\"Initialized CategoryAwareTrainingLabelCorrector\")\n",
    "        self.logger.info(f\"Total training samples: {len(train_df)}\")\n",
    "        self.logger.info(f\"Categories: {list(category_attribute_mapping.keys())}\")\n",
    "        self.logger.info(f\"Similarity threshold: {similarity_threshold}\")\n",
    "        self.logger.info(f\"Number of similar images to consider: {num_similar}\")\n",
    "        self.logger.info(f\"Detailed logs will be saved to: {log_file}\")\n",
    "        \n",
    "    def _log_similar_images(self, image_path: str, similar_results: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Log detailed information about similar images.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the source image\n",
    "            similar_results: DataFrame with similar images\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"\\n--- Similar Images for {os.path.basename(image_path)} ---\")\n",
    "        for _, row in similar_results.iterrows():\n",
    "            self.logger.info(\n",
    "                f\"Similar Image: {row['filename']} \"\n",
    "                f\"(Similarity: {row['similarity']:.4f})\"\n",
    "            )\n",
    "    \n",
    "    def get_majority_label(self, similar_results: pd.DataFrame, \n",
    "                            category: str,\n",
    "                            attr_column: str) -> Optional[Any]:\n",
    "        \"\"\"\n",
    "        Find the majority label from similar images for a specific attribute.\n",
    "        \"\"\"\n",
    "        # Previous implementation remains the same, but add logging\n",
    "        # Filter by similarity threshold\n",
    "        filtered_results = similar_results[\n",
    "            similar_results['similarity'] >= self.similarity_threshold\n",
    "        ]\n",
    "        \n",
    "        if len(filtered_results) == 0:\n",
    "            self.logger.warning(\n",
    "                f\"No similar images above threshold for category {category}, \"\n",
    "                f\"attribute {attr_column}\"\n",
    "            )\n",
    "            return None\n",
    "            \n",
    "        # Get labels for similar images\n",
    "        similar_labels = []\n",
    "        for filename in filtered_results['filename']:\n",
    "            if filename in self.filename_to_idx:\n",
    "                idx = self.filename_to_idx[filename]\n",
    "                label = self.train_df.at[idx, attr_column]\n",
    "                if pd.notna(label):  # Only consider non-null labels\n",
    "                    similar_labels.append(label)\n",
    "        \n",
    "        if not similar_labels:\n",
    "            self.logger.warning(\n",
    "                f\"No valid labels found for similar images in \"\n",
    "                f\"category {category}, attribute {attr_column}\"\n",
    "            )\n",
    "            return None\n",
    "            \n",
    "        # Find majority label\n",
    "        label_counts = Counter(similar_labels)\n",
    "        majority_label, count = label_counts.most_common(1)[0]\n",
    "        total_count = sum(label_counts.values())\n",
    "        \n",
    "        # Log label distribution\n",
    "        self.logger.info(\n",
    "            f\"Label distribution for {category} - {attr_column}: \"\n",
    "            f\"{dict(label_counts)} (Total: {total_count})\"\n",
    "        )\n",
    "        \n",
    "        # Return majority label only if it appears in more than 50% of similar images\n",
    "        if count / total_count > 0.5:\n",
    "            self.logger.info(\n",
    "                f\"Majority label found: {majority_label} \"\n",
    "                f\"(Confidence: {count/total_count:.2%})\"\n",
    "            )\n",
    "            return majority_label\n",
    "        \n",
    "        self.logger.info(\n",
    "            f\"No confident majority label for {category} - {attr_column}. \"\n",
    "            f\"Keeping original label.\"\n",
    "        )\n",
    "        return None\n",
    "    \n",
    "    def correct_labels(self, image_folder: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Correct labels in the training dataset using similarity-based majority voting.\n",
    "        \"\"\"\n",
    "        corrected_df = self.train_df.copy()\n",
    "        corrections_log = []\n",
    "        total_processed = 0\n",
    "        \n",
    "        # Initialize correction counters for each category and attribute\n",
    "        corrections_made = {\n",
    "            category: {attr_name: 0 for attr_name in attrs.keys()}\n",
    "            for category, attrs in self.category_attribute_mapping.items()\n",
    "        }\n",
    "        \n",
    "        # Total images per category for statistical insights\n",
    "        category_totals = self.train_df['Category'].value_counts().to_dict()\n",
    "        \n",
    "        for idx, row in self.train_df.iterrows():\n",
    "            category = row['Category']\n",
    "            if category not in self.category_attribute_mapping:\n",
    "                continue\n",
    "                \n",
    "            image_path = f\"{image_folder}/{str(row['id']).zfill(6)}.png\"\n",
    "            total_processed += 1\n",
    "            \n",
    "            try:\n",
    "                # Find similar images\n",
    "                similar_results = self.searcher.find_similar_images(\n",
    "                    image_path, \n",
    "                    k=self.num_similar\n",
    "                )\n",
    "                \n",
    "                # Log similar images details\n",
    "                self._log_similar_images(image_path, similar_results)\n",
    "                \n",
    "                # Get relevant attributes for this category\n",
    "                category_attrs = self.get_category_attributes(category)\n",
    "                \n",
    "                # Process each attribute\n",
    "                for attr_column in category_attrs:\n",
    "                    attr_name = self.get_attribute_name(category, attr_column)\n",
    "                    \n",
    "                    majority_label = self.get_majority_label(\n",
    "                        similar_results,\n",
    "                        category,\n",
    "                        attr_column\n",
    "                    )\n",
    "                    \n",
    "                    if majority_label is not None and (\n",
    "                        pd.isna(row[attr_column]) or majority_label != row[attr_column]\n",
    "                    ):\n",
    "                        old_value = corrected_df.at[idx, attr_column]\n",
    "                        corrected_df.at[idx, attr_column] = majority_label\n",
    "                        corrections_made[category][attr_name] += 1\n",
    "                        \n",
    "                        # Log the correction with detailed information\n",
    "                        corrections_log.append({\n",
    "                            'image_id': row['id'],\n",
    "                            'category': category,\n",
    "                            'attribute': attr_name,\n",
    "                            'attribute_column': attr_column,\n",
    "                            'old_value': old_value,\n",
    "                            'new_value': majority_label,\n",
    "                            'num_similar_images': len(similar_results),\n",
    "                            'avg_similarity': similar_results['similarity'].mean()\n",
    "                        })\n",
    "                        \n",
    "                        self.logger.info(\n",
    "                            f\"Corrected label for Image {row['id']}:\\n\"\n",
    "                            f\"  Category: {category}\\n\"\n",
    "                            f\"  Attribute: {attr_name}\\n\"\n",
    "                            f\"  Old Value: {old_value}\\n\"\n",
    "                            f\"  New Value: {majority_label}\"\n",
    "                        )\n",
    "                \n",
    "                # Progress tracking\n",
    "                if total_processed % 100 == 0:\n",
    "                    self.logger.info(f\"Processed {total_processed}/{len(self.train_df)} images\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error processing image {image_path}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        # Create corrections log DataFrame\n",
    "        corrections_log_df = pd.DataFrame(corrections_log)\n",
    "        \n",
    "        # Log comprehensive correction statistics\n",
    "        self.logger.warning(\"\\nFinal Correction Statistics:\")\n",
    "        total_corrections = 0\n",
    "        for category, attr_corrections in corrections_made.items():\n",
    "            category_corrections = sum(attr_corrections.values())\n",
    "            total_corrections += category_corrections\n",
    "            category_total = category_totals.get(category, 0)\n",
    "            \n",
    "            self.logger.warning(f\"\\n{category}:\")\n",
    "            for attr_name, count in attr_corrections.items():\n",
    "                percentage = (count / category_total) * 100 if category_total > 0 else 0\n",
    "                self.logger.warning(f\"  {attr_name}: {count} corrections ({percentage:.2f}%)\")\n",
    "            \n",
    "            self.logger.warning(\n",
    "                f\"  Total corrections for {category}: {category_corrections} \"\n",
    "                f\"({category_corrections/category_total*100:.2f}%)\"\n",
    "            )\n",
    "        \n",
    "        self.logger.warning(\n",
    "            f\"\\nTotal Corrections Across All Categories: {total_corrections} \"\n",
    "            f\"({total_corrections/len(self.train_df)*100:.2f}%)\"\n",
    "        )\n",
    "        \n",
    "        return corrected_df, corrections_log_df\n",
    "\n",
    "def correct_training_labels(\n",
    "    train_df: pd.DataFrame,\n",
    "    image_folder: str,\n",
    "    category_attribute_mapping: Dict[str, Dict[str, str]],\n",
    "    output_path: str,\n",
    "    log_dir: Optional[str] = None,\n",
    "    num_similar: int = 10,\n",
    "    similarity_threshold: float = 0.7\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Correct labels in the training dataset and save the results with comprehensive logging.\n",
    "    \"\"\"\n",
    "    # Configure global logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    \n",
    "    # Initialize the label corrector\n",
    "    corrector = CategoryAwareTrainingLabelCorrector(\n",
    "        similarity_searcher=searcher,\n",
    "        train_df=train_df,\n",
    "        category_attribute_mapping=category_attribute_mapping,\n",
    "        num_similar=num_similar,\n",
    "        similarity_threshold=similarity_threshold,\n",
    "        log_dir=log_dir\n",
    "    )\n",
    "    \n",
    "    # Correct labels\n",
    "    corrected_df, corrections_log_df = corrector.correct_labels(\n",
    "        image_folder=image_folder\n",
    "    )\n",
    "    \n",
    "    # Save corrected dataset\n",
    "    corrected_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nCorrected dataset saved to: {output_path}\")\n",
    "    \n",
    "    # Save corrections log\n",
    "    log_path = output_path.replace('.csv', '_corrections_log.csv')\n",
    "    corrections_log_df.to_csv(log_path, index=False)\n",
    "    print(f\"Corrections log saved to: {log_path}\")\n",
    "\n",
    "# Run the label correction\n",
    "correct_training_labels(\n",
    "    train_df=train_df,\n",
    "    image_folder='/scratch/data/m23csa016/meesho_data/train_images_bg_removed',\n",
    "    category_attribute_mapping=category_class_attribute_mapping,  # Your mapping\n",
    "    output_path='corrected_train_labels.csv',\n",
    "    num_similar=50,\n",
    "    similarity_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
